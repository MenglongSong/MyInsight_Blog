## Scrapy问题

### 进行大规模抓取数据



### 参考
[scrapy 下载图片到 4w 张左右总是会卡住](https://www.v2ex.com/amp/t/365631)  
[使用python scrapy框架,循环爬取URL, 每次运行一段时间后直接卡死,没有任何报错](http://www.codes51.com/itwd/4379484.html)  
[scrapy假死是怎么回事？](https://segmentfault.com/q/1010000004126786)  

[使用scrapy进行大规模抓取](https://blog.csdn.net/leoking01/article/details/41041455)  
[解决Scrapy性能问题——案例四（响应太多导致溢出）](https://blog.csdn.net/Q_AN1314/article/details/51253675)  
[解决Scrapy性能问题——案例五（Item并发太多导致溢出）](https://blog.csdn.net/weixin_40976261/article/details/89034314)  
[Scrapy 轻松定制网络爬虫](http://blog.pluskid.org/?p=366)  
[Scrapy 学习笔记 -- 解决分页爬取的问题](https://www.jianshu.com/p/0c957c57ae10)  
[Scrapy抓取在不同级别Request之间传递参数](https://www.jianshu.com/p/de61ed0f961d)  

[同时运行多个scrapy爬虫的几种方法（自定义scrapy项目命令）](https://www.cnblogs.com/rwxwsblog/p/4578764.html)  




