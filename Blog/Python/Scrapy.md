## Scrapy一些链接

### 参考
[Scrapy入门教程](https://www.cnblogs.com/txw1958/archive/2012/07/16/scrapy-tutorial.html)  


[爬虫代理卡住：关于requests里的timeout()](https://blog.csdn.net/NRlovestudy/article/details/88311814)  
[接口自动化之requests学习（五）--timeout的用法](https://blog.csdn.net/doulihang/article/details/83042177)  
[知识点讲解二：关于requests里的timeout()](https://blog.csdn.net/qq_38251616/article/details/81813793)  
[爬虫-timeout机制-避免网页假死 长时间不加载](https://blog.csdn.net/qq_25439417/article/details/83033450)  
[用scrapy框架下载图片时可能存在的问题](https://blog.csdn.net/JLaiRen/article/details/84945173)  
[爬虫--Scrapy之Downloader Middleware](https://www.cnblogs.com/zhuifeng-mayi/p/9773656.html)  


[妹子图爬虫，最重要的是请求头headers设置'Referer':'http://www.mzitu.com/'](https://blog.csdn.net/Jamin2018/article/details/78772628)  
[爬虫之UserAgent的获得方法](https://blog.csdn.net/python_neophyte/article/details/82491359)  
[关于网页referer以及破解referer反爬虫的办法](https://blog.csdn.net/python_neophyte/article/details/82562330)  

[scrapy实战：伪造headers的多种实现](https://blog.csdn.net/weixin_43430036/article/details/84851714)  
[scrapy学习笔记（三）实战练习](https://www.imooc.com/article/21840)  
[Scrapy 示例 —— Web 爬虫框架](https://www.oschina.net/translate/scrapy-demo)  

[使用scrapy做爬虫遇到的一些坑：网站常用的反爬虫策略，如何机智的躲过反爬虫Crawled (403)](https://blog.csdn.net/weixin_41931602/article/details/80679623)  
[使用scrapy做爬虫遇到的一些坑：爬虫使用scrapy爬取网页返回403错误大全以及解决方案](https://blog.csdn.net/weixin_41931602/article/details/80200695)  

[Python爬虫---处理HTTPS请求 SSL证书验证](https://blog.csdn.net/tao3741/article/details/76554878)  


[Scrapy官网](https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/practices.html)  

